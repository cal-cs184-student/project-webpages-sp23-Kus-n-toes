<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<style>
  body {
    padding: 100px;
    width: 1000px;
    margin: auto;
    text-align: left;
    font-weight: 300;
    font-family: 'Open Sans', sans-serif;
    color: #121212;
  }
  h1, h2, h3, h4 {
    font-family: 'Source Sans Pro', sans-serif;
  }
  .center {
    display: block;
    margin-left: auto;
    margin-right: auto;
    width: 50%;
  }
</style>
<title>CS 184 Rasterizer</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">
</head>


<body>

<h1 align="middle">CS 184: Computer Graphics and Imaging, Spring 2023</h1>
<h1 align="middle">Project 1: Rasterizer</h1>
<h2 align="middle">Eric Kusnanto, CS184-SP23</h2>

<br><br>

<div>

<h2 align="middle">Overview</h2>
<p>Give a high-level overview of what you implemented in this project. Think about what you've built as a whole. Share your thoughts on what interesting things you've learned from completing the project.</p>

  <p>In this project, we implemented nearly all the steps needed for a rasterization pipeline. We created the infrastructure to handle the rasterization of points, lines, and triangles, which combined can form a vast majority of images and shapes. We implemented texture mapping and transforms, allowing objects to scale and follow the texture of a mipmap. We also implemented many anti-aliasing techniques to make our images much more accurate to what was intended to be depicted, including supersampling, bilinear interpolation of textures and of mipmaps.</p>
<h2 align="middle">Section I: Rasterization</h2>

<h3 align="middle">Part 1: Rasterizing single-color triangles</h3>
  <p>We rasterize a triangle given its vertices onto the frame buffer by sampling the middle of each pixel and checking
    if it is inside each line connecting the vertices, and filling the entire pixel with that color if it is. This check
  is done by doing the Three Line Test described in lecture, where we compute whether our current sampled pixel falls
  in the right half-plane for each edge. To take care of edge cases, we check for equality (where the middle of the pixel
  is directly on the line) and we account for both winding directions by checking for the intersection of the 3 half-planes
  (i.e. if the line tests are all greater than or equal to 0 or all less than or equal to 0). My algorithm is optimized to
  only sample pixels in the 'bounding box' of the triangle by only iterating from the minimum coordinates of each vertex to
  the maximum.</p>

  <!-- TODO: add pngs -->
  <div align="left">
    <table style="width=100">
      <td>
        <img src="task1.png" align="left" width="400px"/>
        <br>
      </td>
      <td>
        <figcaption align="left">Here is an interesting case of rasterizing a very sharp angle of a triangle, creating a non-contiguous artifact.</figcaption>
        <br>
      </td>
    </table>
  </div>


<h3 align="middle">Part 2: Antialiasing triangles</h3>
  Walk through your supersampling algorithm and data structures. Why is supersampling useful?
  What modifications did you make to the rasterization pipeline in the process?
  Explain how you used supersampling to antialias your triangles.

  <br>
  <p>To achieve supersampling on our triangles, we had to adjust our initial rasterize_triangle function as well as the way we store the frame itself.
    To be able to sample the 'mini-pixels' inside each pixel that will be displayed on the frame buffer, we resized a sample buffer to become a much
    larger array of mini-pixels, scaling by the square root of the sample rate. We also scale the triangle's vertices to fit the new array, and apply
    the same Three Line test on each mini-pixel of the sample buffer to determine if they fall inside the corresponding triangle, iterating through a
    resized bounding box for each triangle object. Then, we take the colors of the mini-pixels inside each pixel, and downsample to get the average
    color to resolve to the frame buffer and display. This triangle supersampling is useful to reduce the visibility of 'jaggies', by averaging down
    the color so that it more closely resembles how much of each pixel is inside the triangle. This process modifies the pipeline by separating out
    the step where we rasterize each triangle and the step where we directly fill up the frame buffer to be displayed. We first supersample each pixel
    with their individual mini-pixels on every single triangle object, before we downsample a pixel's average color, which may contain lines or even
    multiple triangles, that gets sent to the frame buffer to be displayed. As supersampling samples multiple points in each pixel, this antialiases
    the triangles by averaging out edge cases with the color of the background or any other objects that have been rasterized triangles.
  </p>

  <br>

  <div align="middle">
    <table style="width=100%" >
      <tr>
        <td colspan="2" align="center">
          <img src="task2_sr1.png" align="middle" width="400px"/>
          <figcaption align="middle">Sharp corner of a rasterized triangle without supersampling (sample rate of 1).</figcaption>
        </td>
      </tr>
      <tr>
        <td>
          <img src="task2_sr4.png" align="middle" width="400px"/>
          <figcaption align="middle">Sharp corner with a sample rate of 4.</figcaption>
        </td>
        <td>
          <img src="task2_sr16.png" align="middle" width="400px"/>
          <figcaption align="middle">Sharp corner with a sample rate of 16.</figcaption>
        </td>
      </tr>
    </table>
  </div>

  <br>

  <p>There are key differences between these supersampled corners. The one without any supersampling only samples the very midpoint
  of each pixel, so there are some pixels near the triangle's corner that 'float' separately from the main shape. However, with
  supersampling at a sample rate of 4, the sharp corner becomes completely contiguous again, as we sample four points now and
    average out the color. This leads to the color of these new pixels to blend more with the background, looking more faded.
  Finally, the one that supersamples 16 points to one pixel seems to elongate the corner even further, showing that the previous
  two images didn't correctly express exactly where this vertex of the triangle even was.</p>


  <h3 align="middle">Part 3: Transforms</h3>


  <img src="task3.png" align="middle" width="600px" class="center"/>

  <p>
  I tried making a purple man saluting in his fancy clothes. I rotated the arms and legs, one of them rotating before scaling and the other scaling before rotating as both led to vastly different outcomes, leading to rhombus shaped legs. I also added eyes and had to translate them relative to the body, though adding them to the head transforms would be a smarter idea as eyes would stay relative to the head if the head changes position. I also realized that each rectangle/rhombus was made up of two triangles, so I changed the color of some of them to make faces and pant designs. Finally, I slightly changed one of the vertices on a head triangle, to make the effect of a helmet or cap.
  </p>


<h2 align="middle">Section II: Sampling</h2>

<h3 align="middle">Part 4: Barycentric coordinates</h3>

  Explain barycentric coordinates in your own words and use an image to aid you in your explanation. One idea is to use a svg file
  that plots a single triangle with one red, one green, and one blue vertex, which should produce a smoothly blended color triangle.
  Show a png screenshot of svg/basic/test7.svg with default viewing parameters and sample rate 1. If you make any additional
  images with color gradients, include them.

  <img src="task4_barycentric.png" align="middle" width="600px" class="center"/>
  <figcaption align="middle">In this triangle, we have extrapolated the color of each pixel inside the triangle using linear interpolation on the barycentric coordinates from each vertex. The top left vertex has an Color attribute of solely blue, the bottom left of solely green, and the right vertex of solely red, creating a triangle with a rainbow of colors with weighted combinations between the three primary ones.</figcaption>


  <p>
  Barycentric coordinates are the coordinates of a point (&alpha;, &beta;, &gamma;) relative to the vertices of a triangle and prove to be useful for linearly interpolating any quantity or attribute from the vertices onto all points inside the triangle. Any point on a coordinate plane can have its barycentric coordinates evaluated by knowing the coordinates of a triangle's vertices and finding the proportional distance from each vertex to the point. If any single one of these weights is less than zero, then that means that the point chosen is not inside the triangle. These barycentric weights (&alpha;, &beta;, &gamma;) can then be used in a linear combination with an attribute V, such as color or texture, that exists on each vertex to linearly interpolate what attribute value would a point on the triangle theoretically have, which ends up being tremendously useful throughout the project.
</p>




  <img src="task4_test.png" align="middle" width="600px" class="center"/>
  <figcaption align="middle">A color wheel made up of lots of triangles with interpolated colors in each pixel.</figcaption>




  <h3 align="middle">Part 5: "Pixel sampling" for texture mapping</h3>

<p>
  Pixel sampling is where we take a given pixel we want to color, transform it into u,v coordinates onto the texture space, and sample the colors from the nearby pixels on the relevant mipmap. Here, we implemented this by taking the current supersampling floats we are iterating through and finding its barycentric coordinates on the current triangle. By multiplying these weights with the x, y coordinates of the vertices, we can move into texture space with the floats u,v, where we can then choose between two sampling methods with the nearby points in texture space. The simpler one, nearest neighbor, finds the single closest pixel in our set mipmap, done by rounding our float to integer pixel coordinates, and sampling that one color as our pixel color. The later bilinear, takes in the four integer pixel coordinates closest to our float, found by using ceil() and floor() functions, and linearly interpolating a color that takes in account each corner’s color and their relative distance from our sampled location. We did this by doing two linear interpolations on the horizontal axis to find temporary colors of 2 points e, f that align with the float on the vertical axis, and then one final linear interpolation to find the exact color of the sample.
</p>

  <div align="middle">
    <table style="width=100%">
      <tr>
        <td>
          <img src="task5_nearest_sr1.png" align="middle" width="400px"/>
          <figcaption align="middle">Map with nearest neighbor pixel sampling, sample rate of 1.</figcaption>
        </td>
        <td>
          <img src="task5_nearest_sr16.png" align="middle" width="400px"/>
          <figcaption align="middle">Map with nearest neighbor pixel sampling, sample rate of 16.</figcaption>
        </td>
      </tr>
      <br>
      <tr>
        <td>
          <img src="task5_bilinear_sr1.png" align="middle" width="400px"/>
          <figcaption align="middle">Map with bilinear pixel sampling, sample rate of 1.</figcaption>
        </td>
        <td>
          <img src="task5_bilinear_sr16.png" align="middle" width="400px"/>
          <figcaption align="middle">Map with bilinear pixel sampling, sample rate of 16.</figcaption>
        </td>
      </tr>
    </table>
  </div>




  <p>The differences between bilinear and nearest neighbor pixel sampling can be felt on texture maps that ‘bend’ straight lines. On this world map, nearest neighbor sampling with a sample rate of 1 results in discrete, broken up longitudinal lines, while bilinear sampling at rate 1 keeps the lines unbroken, though they are averaged and ‘blurred’ out by the background ocean. Nearest neighbor with a larger sample rate of 16 results in a better representation of the longitudinal and latitudinal lines, similar visually to the bilinear sampling at rate 1, but combining bilinear pixel sampling with a sample rate of 16 results in ‘smoother’ unbroken lines that look more like a continuous visual element than the nearest neighbor one. This large difference, amongst others, is due to the fact that nearest neighbor only ends up sampling and taking into consideration one point, so for distinct yet thin visual elements line 1 pixel wide lines, nearest neighbor may end up not even sampling the distinct pixel on texture space.</p>
<h3 align="middle">Part 6: "Level sampling" with mipmaps for texture mapping</h3>

  <p>Level sampling takes the difference in sizes between pixels on screen compared to pixels in texture space using partial derivatives so that we can find the best accommodating mipmap level to use. We implemented it by pre-computing using barycentric coordinates the unit vector in both u and v directions. Then, we took the largest vector and performed a log operation on it to get a float. In nearest level sampling, we simply rounded this to the closest mipmap level available to us, and in the other option we simply linearly interpolated the colors from the closest two integer mipmap levels according to their distance from the float.</p>

  <p>Of course, the more we want to anti-alias, the more computationally expensive our rasterization pipeline becomes. Increasing sample rate, while getting rid of ‘jaggies’ forces much more samples to be taken, plus the overhead of downsampling and averaging out the actual pixel color, all slowing down performance. For texture mapping, the linear level sampling requires memory access to two separate mipmaps, becoming more expensive to perform than nearest level sampling.</p>

  <div align="middle">
    <table style="width=100%">
      <tr>
        <td>
          <img src="task6_lzero_pnearest.png" align="middle" width="400px"/>
          <figcaption align="middle">Face with level zero mipmap and nearest neighbor pixel sampling.</figcaption>
        </td>
        <td>
          <img src="task6_lzero_pbilinear.png" align="middle" width="400px"/>
          <figcaption align="middle">Face with level zero mipmap and bilinear pixel sampling.</figcaption>
        </td>
      </tr>
      <br>
      <tr>
        <td>
          <img src="task6_lnearest_pnearest.png" align="middle" width="400px"/>
          <figcaption align="middle">Face with nearest mipmap level and nearest neighbor pixel sampling.</figcaption>
        </td>
        <td>
          <img src="task6_lnearest_pbilinear.png" align="middle" width="400px"/>
          <figcaption align="middle">Face with nearest mipmap level and bilinear pixel sampling.</figcaption>
        </td>
      </tr>
    </table>
  </div>

<h2 align="middle">Section III: Art Competition</h2>
<p>If you are not participating in the optional art competition, don't worry about this section!</p>

<h3 align="middle">Part 7: Draw something interesting!</h3>

</body>
</html>
